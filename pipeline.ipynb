{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Optional, List\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from skimage.restoration import estimate_sigma\n",
        "import threading\n",
        "import queue\n",
        "\n",
        "@dataclass\n",
        "class VideoMetadata:\n",
        "    width: int\n",
        "    height: int\n",
        "    fps: int\n",
        "\n",
        "class VideoProcessingError(Exception):\n",
        "    pass\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, input_path: str, output_path: str):\n",
        "        self.input_path = input_path\n",
        "        self.output_path = output_path\n",
        "        self.video_capture = None\n",
        "        self.output_writer = None\n",
        "        self.metadata = None\n",
        "\n",
        "    def initialize(self) -> VideoMetadata:\n",
        "        if not os.path.exists(self.input_path):\n",
        "            raise VideoProcessingError(f\"Video file not found: {self.input_path}\")\n",
        "\n",
        "        self.video_capture = cv2.VideoCapture(self.input_path)\n",
        "        if not self.video_capture.isOpened():\n",
        "            raise VideoProcessingError(f\"Error opening video file: {self.input_path}\")\n",
        "\n",
        "        width = int(self.video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(self.video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(self.video_capture.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        self.metadata = VideoMetadata(width, height, fps)\n",
        "        return self.metadata\n",
        "\n",
        "    def create_writer(self):\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        self.output_writer = cv2.VideoWriter(\n",
        "            self.output_path,\n",
        "            fourcc,\n",
        "            self.metadata.fps,\n",
        "            (self.metadata.width, self.metadata.height)\n",
        "        )\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        ret, frame = self.video_capture.read()\n",
        "        if not ret:\n",
        "            self.release()\n",
        "            raise StopIteration\n",
        "        return frame\n",
        "\n",
        "    def write_frame(self, frame):\n",
        "        if self.output_writer is not None:\n",
        "            self.output_writer.write(frame)\n",
        "\n",
        "    def release(self):\n",
        "        if self.video_capture is not None:\n",
        "            self.video_capture.release()\n",
        "        if self.output_writer is not None:\n",
        "            self.output_writer.release()\n",
        "\n",
        "class FrameBuffer:\n",
        "    def __init__(self, size: int):\n",
        "        self.size = size\n",
        "        self.buffer = []\n",
        "\n",
        "    def add(self, frame):\n",
        "        if len(self.buffer) == self.size:\n",
        "            self.buffer.pop(0)\n",
        "        self.buffer.append(frame)\n",
        "\n",
        "    def is_full(self):\n",
        "        return len(self.buffer) == self.size\n",
        "\n",
        "    def get_current(self):\n",
        "        return self.buffer[len(self.buffer) // 2]\n",
        "\n",
        "class ImprovedFaceDetector:\n",
        "    def __init__(self):\n",
        "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        self.confidence = 0.0\n",
        "\n",
        "    def detect(self, frame: np.ndarray) -> Optional[Tuple[int, int, int, int]]:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "        if len(faces) > 0:\n",
        "            self.confidence = faces[0][2] * faces[0][3] / (frame.shape[0] * frame.shape[1])  # Simple confidence metric\n",
        "            return tuple(faces[0])\n",
        "        return None\n",
        "\n",
        "    def crop_face_with_padding(self, frame: np.ndarray, face_coords: Tuple[int, int, int, int]) -> np.ndarray:\n",
        "        x, y, w, h = face_coords\n",
        "        padding = int(min(w, h) * 0.1)  # 10% padding\n",
        "        x1, y1 = max(0, x - padding), max(0, y - padding)\n",
        "        x2, y2 = min(frame.shape[1], x + w + padding), min(frame.shape[0], y + h + padding)\n",
        "        return frame[y1:y2, x1:x2]\n",
        "\n",
        "class NoiseEstimator:\n",
        "    def estimate_noise_level(self, image: np.ndarray) -> float:\n",
        "        try:\n",
        "            if len(image.shape) == 3:\n",
        "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            else:\n",
        "                gray = image\n",
        "            sigma_est = estimate_sigma(gray, channel_axis=None)\n",
        "            return sigma_est\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Noise estimation failed: {e}\")\n",
        "            return 0.1\n",
        "\n",
        "class NoiseReducer:\n",
        "    def __init__(self):\n",
        "        self.bilateral_diameter = 9\n",
        "        self.sigma_color = 75\n",
        "        self.sigma_space = 75\n",
        "\n",
        "    def reduce_noise(self, image: np.ndarray, noise_level: float) -> np.ndarray:\n",
        "        sigma_color = self.sigma_color * (noise_level / 0.1)\n",
        "        sigma_space = self.sigma_space * (noise_level / 0.1)\n",
        "\n",
        "        denoised = cv2.bilateralFilter(image, self.bilateral_diameter, sigma_color, sigma_space)\n",
        "\n",
        "        if noise_level > 0.2:\n",
        "            denoised = cv2.GaussianBlur(denoised, (5, 5), 0.5)\n",
        "\n",
        "        return denoised\n",
        "\n",
        "class LightingEnhancer:\n",
        "    def __init__(self):\n",
        "        self.clip_limit = 3.0\n",
        "        self.tile_grid_size = (8, 8)\n",
        "\n",
        "    def enhance_lighting(self, image: np.ndarray) -> np.ndarray:\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l_channel = lab[:,:,0]\n",
        "\n",
        "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
        "\n",
        "        enhanced_l = clahe.apply(l_channel)\n",
        "        lab[:,:,0] = enhanced_l\n",
        "        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "class AdaptiveFaceEnhancer:\n",
        "    def __init__(self):\n",
        "        self.sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
        "        model_path = \"EDSR_x4.pb\"  # You'll need to download this file\n",
        "        try:\n",
        "            self.sr.readModel(model_path)\n",
        "            self.sr.setModel(\"edsr\", 4)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load super-resolution model: {e}\")\n",
        "            self.sr = None\n",
        "        self.quality_score = 0.0\n",
        "\n",
        "    def select_model(self, image: np.ndarray) -> 'AdaptiveFaceEnhancer':\n",
        "        self.quality_score = self.assess_quality(image)\n",
        "        return self\n",
        "\n",
        "    def assess_quality(self, image: np.ndarray) -> float:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        return min(laplacian_var / 500, 1.0)  # Normalize to [0, 1]\n",
        "\n",
        "    def enhance(self, image: np.ndarray) -> np.ndarray:\n",
        "        if self.sr is not None and self.quality_score < 0.5:  # Only apply SR if quality is low\n",
        "            try:\n",
        "                return self.sr.upsample(image)\n",
        "            except Exception as e:\n",
        "                print(f\"Super-resolution failed: {e}\")\n",
        "        return cv2.resize(image, (image.shape[1] * 2, image.shape[0] * 2), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "class FaceReintegrator:\n",
        "    def blend(self, original: np.ndarray, enhanced_face: np.ndarray, face_coords: Tuple[int, int, int, int]) -> np.ndarray:\n",
        "        x, y, w, h = face_coords\n",
        "        enhanced_face_resized = cv2.resize(enhanced_face, (w, h))\n",
        "\n",
        "        mask = np.zeros(original.shape[:2], dtype=np.float64)\n",
        "        cv2.ellipse(mask, center=(x + w//2, y + h//2), axes=(w//2, h//2), angle=0, startAngle=0, endAngle=360, color=(1, 1, 1), thickness=-1)\n",
        "        mask = cv2.GaussianBlur(mask, (w//15, h//15), 0)\n",
        "        mask = np.dstack([mask] * 3)\n",
        "\n",
        "        original_face_area = original[y:y+h, x:x+w]\n",
        "        blended = mask * enhanced_face_resized + (1 - mask) * original_face_area\n",
        "        original[y:y+h, x:x+w] = blended.astype(np.uint8)\n",
        "\n",
        "        return original\n",
        "\n",
        "class EnhancementStatsCollector:\n",
        "    def __init__(self):\n",
        "        self.frame_count = 0\n",
        "        self.total_noise_level = 0\n",
        "        self.total_face_confidence = 0\n",
        "        self.total_quality_score = 0\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def update(self, noise_level: float, face_confidence: float, quality_score: float):\n",
        "        self.frame_count += 1\n",
        "        self.total_noise_level += noise_level\n",
        "        self.total_face_confidence += face_confidence\n",
        "        self.total_quality_score += quality_score\n",
        "\n",
        "    def get_stats(self) -> dict:\n",
        "        processing_time = time.time() - self.start_time\n",
        "        return {\n",
        "            \"processed_frames\": self.frame_count,\n",
        "            \"average_noise_level\": self.total_noise_level / max(1, self.frame_count),\n",
        "            \"average_face_confidence\": self.total_face_confidence / max(1, self.frame_count),\n",
        "            \"average_quality_score\": self.total_quality_score / max(1, self.frame_count),\n",
        "            \"processing_time\": processing_time,\n",
        "            \"fps\": self.frame_count / processing_time if processing_time > 0 else 0\n",
        "        }\n",
        "\n",
        "def process_frame(frame, face_detector, noise_estimator, noise_reducer, lighting_enhancer, face_enhancer, face_reintegrator, stats_collector):\n",
        "    face_coords = face_detector.detect(frame)\n",
        "    if face_coords:\n",
        "        face_frame = face_detector.crop_face_with_padding(frame, face_coords)\n",
        "\n",
        "        noise_level = noise_estimator.estimate_noise_level(face_frame)\n",
        "        denoised_frame = noise_reducer.reduce_noise(face_frame, noise_level)\n",
        "\n",
        "        lighting_enhanced = lighting_enhancer.enhance_lighting(denoised_frame)\n",
        "\n",
        "        enhanced_face = face_enhancer.select_model(lighting_enhanced).enhance(lighting_enhanced)\n",
        "\n",
        "        frame = face_reintegrator.blend(frame, enhanced_face, face_coords)\n",
        "\n",
        "        stats_collector.update(noise_level, face_detector.confidence, face_enhancer.quality_score)\n",
        "\n",
        "    return frame\n",
        "\n",
        "def process_video(input_path: str, output_path: str):\n",
        "    video_processor = VideoProcessor(input_path, output_path)\n",
        "    face_detector = ImprovedFaceDetector()\n",
        "    noise_estimator = NoiseEstimator()\n",
        "    noise_reducer = NoiseReducer()\n",
        "    lighting_enhancer = LightingEnhancer()\n",
        "    face_enhancer = AdaptiveFaceEnhancer()\n",
        "    face_reintegrator = FaceReintegrator()\n",
        "    stats_collector = EnhancementStatsCollector()\n",
        "\n",
        "    try:\n",
        "        video_processor.initialize()\n",
        "        video_processor.create_writer()\n",
        "\n",
        "        frame_buffer = FrameBuffer(size=5)\n",
        "        frame_queue = queue.Queue(maxsize=10)\n",
        "        result_queue = queue.Queue()\n",
        "\n",
        "        def worker():\n",
        "            while True:\n",
        "                frame = frame_queue.get()\n",
        "                if frame is None:\n",
        "                    break\n",
        "                processed_frame = process_frame(frame, face_detector, noise_estimator, noise_reducer,\n",
        "                                                lighting_enhancer, face_enhancer, face_reintegrator, stats_collector)\n",
        "                result_queue.put(processed_frame)\n",
        "                frame_queue.task_done()\n",
        "\n",
        "        num_threads = 4\n",
        "        threads = []\n",
        "        for _ in range(num_threads):\n",
        "            t = threading.Thread(target=worker)\n",
        "            t.start()\n",
        "            threads.append(t)\n",
        "\n",
        "        for frame in video_processor:\n",
        "            frame_buffer.add(frame)\n",
        "            if frame_buffer.is_full():\n",
        "                frame_queue.put(frame_buffer.get_current())\n",
        "\n",
        "            if not result_queue.empty():\n",
        "                processed_frame = result_queue.get()\n",
        "                video_processor.write_frame(processed_frame)\n",
        "\n",
        "        # Process remaining frames\n",
        "        while not frame_buffer.buffer:\n",
        "            frame_queue.put(frame_buffer.buffer.pop(0))\n",
        "\n",
        "        # Signal threads to exit\n",
        "        for _ in range(num_threads):\n",
        "            frame_queue.put(None)\n",
        "\n",
        "        # Wait for all threads to complete\n",
        "        for t in threads:\n",
        "            t.join()\n",
        "\n",
        "        # Write any remaining processed frames\n",
        "        while not result_queue.empty():\n",
        "            processed_frame = result_queue.get()\n",
        "            video_processor.write_frame(processed_frame)\n",
        "\n",
        "    except VideoProcessingError as e:\n",
        "        print(f\"Error processing video: {e}\")\n",
        "    finally:\n",
        "        video_processor.release()\n",
        "\n",
        "    return stats_collector.get_stats()\n",
        "\n",
        "def main():\n",
        "    input_video = \"/content/D01_20240705162954 (online-video-cutter.com) (1).mp4\"\n",
        "    output_video = \"enhanced_output.mp4\"\n",
        "\n",
        "    if not os.path.exists(input_video):\n",
        "        print(f\"Input video not found: {input_video}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        stats = process_video(input_video, output_video)\n",
        "        print(\"Enhancement Statistics:\", stats)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2VGMiUSvIpe",
        "outputId": "00bc01e0-df87-4657-d978-ed87e8d8cac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not load super-resolution model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"EDSR_x4.pb\" in function 'ReadProtoFromBinaryFile'\n",
            "\n",
            "Warning: Noise estimation failed: PyWavelets is not installed. Please ensure it is installed in order to use this function.\n",
            "Warning: Noise estimation failed: PyWavelets is not installed. Please ensure it is installed in order to use this function.\n",
            "Warning: Noise estimation failed: PyWavelets is not installed. Please ensure it is installed in order to use this function.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Exception in thread Thread-13 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "Thread-12 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "        self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "self.run()    \n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 267, in worker\n",
            "self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 267, in worker\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 238, in process_frame\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 196, in blend\n",
            "ValueError: operands could not be broadcast together with shapes (1080,1920,3) (106,106,3) \n",
            "  File \"<ipython-input-1-012741f6092a>\", line 238, in process_frame\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 196, in blend\n",
            "ValueError: operands could not be broadcast together with shapes (1080,1920,3) (106,106,3) \n",
            "Exception in thread Thread-10 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 267, in worker\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 238, in process_frame\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 196, in blend\n",
            "ValueError: operands could not be broadcast together with shapes (1080,1920,3) (106,106,3) \n",
            "Exception in thread Thread-11 (worker):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 267, in worker\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 238, in process_frame\n",
            "  File \"<ipython-input-1-012741f6092a>\", line 196, in blend\n",
            "ValueError: operands could not be broadcast together with shapes (1080,1920,3) (106,106,3) \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Noise estimation failed: PyWavelets is not installed. Please ensure it is installed in order to use this function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "An3ovw0xxs8t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}